# ------------------- Breusch-Pagan LM Test -------------------
# Test if random effects are preferred over OLS
from statsmodels.stats.diagnostic import het_breuschpagan

ols_model = sm.OLS(y, sm.add_constant(X)).fit()
lm_test = het_breuschpagan(ols_model.resid, sm.add_constant(X))

lm_stat = lm_test[0]
lm_pvalue = lm_test[1]

print("\nBreusch-Pagan LM Test Results:")
print(f"LM Statistic: {lm_stat}")
print(f"P-Value: {lm_pvalue}")
if lm_pvalue < 0.05:
    print("Random effects model is preferred over OLS.")
else:
    print("OLS model may be more appropriate.")

# ------------------- Cross-Validation for Model Comparison -------------------
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Fit fixed effects model on training data
fixed_model_train = PanelOLS(y_train, X_train, entity_effects=True, drop_absorbed=True).fit()

# Fit random effects model on training data
random_model_train = RandomEffects(y_train, X_train).fit()

# Predict and compute MSE
fixed_mse = mean_squared_error(y_test, fixed_model_train.predict(X_test))
random_mse = mean_squared_error(y_test, random_model_train.predict(X_test))

print("\nCross-Validation Results:")
print(f"Fixed Effects MSE: {fixed_mse}")
print(f"Random Effects MSE: {random_mse}")

if fixed_mse < random_mse:
    print("Fixed effects model is preferred based on cross-validation.")
else:
    print("Random effects model is preferred based on cross-validation.")
